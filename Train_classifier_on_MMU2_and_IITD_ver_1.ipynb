{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train classifier on MMU2 and IITD ver 1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jHYzYPxbgkOs",
        "HEg3sY7WV1Kl",
        "DqvXi2SAbSYZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appleBattery/Eye-based-Verification/blob/master/Train_classifier_on_MMU2_and_IITD_ver_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6dDVKemUJs-",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries and dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6g1fgu_A-Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1acf161d-1a2a-44f5-a9a8-da29b7b094dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ertEi3hBMZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import ceil\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHYzYPxbgkOs",
        "colab_type": "text"
      },
      "source": [
        "### Define Custom Neural network for training (Scheme 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQDX5s2cCpKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ef38359-19ba-4435-af9a-8b51e9dedb07"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # this model was working.\n",
        "print(device)\n",
        "\n",
        "class iris_classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(iris_classifier, self).__init__()\n",
        "    # load resNet50\n",
        "    self.resNet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "    # Remove final layer\n",
        "    modules=list(self.resNet50.children())[:-1]\n",
        "    self.resNet50 = torch.nn.Sequential(*modules)\n",
        "\n",
        "    # Flatten output from Global Average Pool of ResNet\n",
        "    self.resNet50.flat = torch.nn.Flatten() \n",
        "    \n",
        "    # freeze all layers of the resNet50\n",
        "    for param in self.resNet50.parameters():\n",
        "      param.requires_grad = False \n",
        "    \n",
        "    # Define the fully connected layers as per Scheme 2\n",
        "    self.fc1 = nn.Linear(2048,128)\n",
        "    self.fc2 = nn.Linear(256,16)\n",
        "    self.fc3 = nn.Linear(16,1)\n",
        "\n",
        "  def forward(self, img1, img2):\n",
        "\n",
        "    # Extract features from resnet\n",
        "    self.resNet50.eval()\n",
        "    out1 = self.resNet50(img1)\n",
        "    out2 = self.resNet50(img2)\n",
        "    \n",
        "    # pass both images through fc1\n",
        "    out1 = F.relu(self.fc1(out1))\n",
        "    out2 = F.relu(self.fc1(out2))\n",
        "\n",
        "    out = torch.cat((out1,out2),1)\n",
        "\n",
        "    out = F.relu(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "classifier = iris_classifier()\n",
        "classifier = classifier.to(device)\n",
        "print(classifier)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "iris_classifier(\n",
            "  (resNet50): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (flat): Flatten()\n",
            "  )\n",
            "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSEs6wrCgdds",
        "colab_type": "text"
      },
      "source": [
        "### Define the dataloader classes for iitd dataset and MMU2 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wspy5IxKVLpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define image transformations to be applied on the images. Normalized to ensure it matches the distribution of Imagenet.\n",
        "autobots = transforms.Compose([transforms.Resize((224,224)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                    std=[0.229, 0.224, 0.225])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWKyYOpLZmCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset must be present in mentioned path in the original directory form. \n",
        "\n",
        "class iitd_dataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.path = '/content/drive/My Drive/iris detection/data/IITD/'\n",
        "  def __len__(self):\n",
        "    # hard-coded total number of image sets. Ideally this must not be done.\n",
        "    # There are 2080 (208 subjects (skipped certain subjects) X 10 possible permutations of 5 images)\n",
        "    # positive image sets for left eye. Same for right eye.\n",
        "    # And rest are negative sets (picked in a idiosyncratic manner). \n",
        "    # Ideally, pick atleast 2-3 times the number of negative images for greater precision.\n",
        "    return 8320\n",
        "  \n",
        "  def get_fldr_idx(self,idx):\n",
        "    \n",
        "    idx += 130 # for skipping over first 13 folders\n",
        "    if (idx >= 261): # skip 27th folder\n",
        "      idx += 10\n",
        "    if (idx >= 541): # skip 55th folder\n",
        "      idx += 10\n",
        "    if (idx >= 641): # skip 65th folder\n",
        "      idx += 10\n",
        "\n",
        "    fldr_idx = (idx//10) + 1\n",
        "    fldr_idx = fldr_idx if ((idx%10)!=0) else (fldr_idx-1)\n",
        "    fldr_idx = str(fldr_idx).zfill(3)\n",
        "    return (fldr_idx,idx)\n",
        "\n",
        "  def pos_permute(self,count):\n",
        "    for i in range(1,5):\n",
        "        for j in range((i+1),6):\n",
        "          count -= 1\n",
        "          if count==0:\n",
        "            return (str(i).zfill(2),str(j).zfill(2))\n",
        "  \n",
        "  def neg_permute(self,count,idx1):\n",
        "    \n",
        "    permute1 = (count//2) if (count%2)==0 else ((count//2)+1)\n",
        "    permute2 = count%5 if (count%5)!=0 else 5\n",
        "    permute1 = str(permute1).zfill(2); permute2 = str(permute2).zfill(2)\n",
        "\n",
        "    if idx1<214:\n",
        "      neg_idx = idx1+count\n",
        "      neg_idx = neg_idx if ((neg_idx!=27)&(neg_idx!=55)&(neg_idx!=65)) else (neg_idx+1) # skip certain folders\n",
        "      neg_idx = str(neg_idx).zfill(3)\n",
        "    else:\n",
        "      neg_idx = idx1-count\n",
        "      neg_idx = str(neg_idx).zfill(3)\n",
        "    return (permute1, permute2, neg_idx)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    idx += 1 #for zero indexing\n",
        "\n",
        "    if idx<=2080: # read positive image sets for left eye\n",
        "      fldr_idx,idx = self.get_fldr_idx(idx)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "      \n",
        "      permute1, permute2 = self.pos_permute(count)\n",
        "      \n",
        "      img1 = Image.open(self.path+fldr_idx+'/'+permute1+'_L.bmp')\n",
        "      img2 = Image.open(self.path+fldr_idx+'/'+permute2+'_L.bmp')\n",
        "      label = 1.\n",
        "\n",
        "    elif (2081<=idx<=4160): # read negative image sets for right eye\n",
        "      fldr_idx,idx = self.get_fldr_idx(idx-2080)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "      \n",
        "      permute1, permute2 = self.pos_permute(count)\n",
        "      permute1 = str(int(permute1)+5).zfill(2); permute2 = str(int(permute2)+5).zfill(2)\n",
        "      \n",
        "      img1 = Image.open(self.path+fldr_idx+'/'+permute1+'_R.bmp')\n",
        "      img2 = Image.open(self.path+fldr_idx+'/'+permute2+'_R.bmp')\n",
        "      label = 1.\n",
        "\n",
        "    elif (4161<=idx<=6240): # read negative image sets for left eye\n",
        "      fldr_idx,idx = self.get_fldr_idx(idx-4160)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "\n",
        "      permute1,permute2,neg_idx = self.neg_permute(count,int(fldr_idx))\n",
        "\n",
        "      img1 = Image.open(self.path+fldr_idx+'/'+permute1+'_L.bmp')\n",
        "      img2 = Image.open(self.path+ neg_idx+'/'+permute2+'_L.bmp')\n",
        "      label = 0.\n",
        "\n",
        "    else: # read negative image sets for right eye\n",
        "      fldr_idx,idx = self.get_fldr_idx(idx-6240)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "\n",
        "      permute1,permute2,neg_idx = self.neg_permute(count,int(fldr_idx))\n",
        "      permute1 = str(int(permute1)+5).zfill(2); permute2 = str(int(permute2)+5).zfill(2)\n",
        "\n",
        "      img1 = Image.open(self.path+fldr_idx+'/'+permute1+'_R.bmp')\n",
        "      img2 = Image.open(self.path+ neg_idx+'/'+permute2+'_R.bmp')\n",
        "      label = 0.\n",
        "    \n",
        "    # It's probably possible to transform and store the images after transformation.\n",
        "    # Will save some time during training.\n",
        "    img1 = autobots(img1) \n",
        "    img2 = autobots(img2)\n",
        "    img1 = img1.type(torch.float16)\n",
        "    img2 = img2.type(torch.float16)\n",
        "    label = torch.tensor([label],dtype=torch.float16)\n",
        "\n",
        "    return (img1,img2,label)\n",
        "\n",
        "iitd = iitd_dataset()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzbWsANDGN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the mmu dataset by index from disk. but note that the 50th image is a bummer because it only got right eye data. \n",
        "\n",
        "class mmu2_dataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.path = '/content/drive/My Drive/iris detection/data/MMU 2/'\n",
        "  def __len__(self):\n",
        "    return 3980\n",
        "\n",
        "  def pos_permute(self,count):\n",
        "    for i in range(1,5):\n",
        "        for j in range((i+1),6):\n",
        "          count -= 1\n",
        "          if count==0:\n",
        "            return (str(i).zfill(2),str(j).zfill(2))\n",
        "  \n",
        "  def neg_permute(self,count,idx1):\n",
        "    \n",
        "    permute1 = (count//2) if (count%2)==0 else ((count//2)+1)\n",
        "    permute2 = count%5 if (count%5)!=0 else 5\n",
        "    permute1 = str(permute1).zfill(2); permute2 = str(permute2).zfill(2)\n",
        "\n",
        "    if idx1<90:\n",
        "      neg_idx = idx1+count\n",
        "      neg_idx = neg_idx if (neg_idx!=50) else 100\n",
        "      neg_idx = str(neg_idx).zfill(2) if (neg_idx<10) else str(neg_idx)\n",
        "    else:\n",
        "      neg_idx = idx1-count\n",
        "      neg_idx = neg_idx if (neg_idx!=50) else 100\n",
        "      neg_idx = str(neg_idx).zfill(2) if (neg_idx<10) else str(neg_idx)\n",
        "    return (permute1, permute2, neg_idx)\n",
        "\n",
        "  def get_file_idx(self,idx):\n",
        "    if idx<=980:\n",
        "      file_idx1 = (idx//20) + 1\n",
        "      file_idx1 = file_idx1 if ((idx%20)!=0) else (file_idx1-1)\n",
        "      file_idx2 = '01' if (((idx%20)<=10)&((idx%20)!=0)) else '02'\n",
        "      file_idx1 = str(file_idx1).zfill(2) if (file_idx1<10) else str(file_idx1)\n",
        "    else:\n",
        "      idx += 10\n",
        "      file_idx1 = (idx//20) + 1\n",
        "      file_idx1 = file_idx1 if ((idx%20)!=0) else (file_idx1-1)\n",
        "      file_idx2 = '01' if (((idx%20)<=10)&((idx%20)!=0)) else '02'\n",
        "      file_idx1 = str(file_idx1).zfill(2) if (file_idx1<10) else str(file_idx1)\n",
        "    return (file_idx1,file_idx2,idx)\n",
        "      \n",
        "  def __getitem__(self, idx):\n",
        "    idx+=1\n",
        "\n",
        "    if idx<=1990: # read positive image sets from disk\n",
        "      file_idx1,file_idx2,idx = self.get_file_idx(idx)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "      \n",
        "      permute1, permute2 = self.pos_permute(count)\n",
        "      \n",
        "      img1 = Image.open(self.path+file_idx1+file_idx2+permute1+'.bmp')\n",
        "      img2 = Image.open(self.path+file_idx1+file_idx2+permute2+'.bmp')\n",
        "      label = 1.\n",
        "    else: # read negative image sets from disk\n",
        "      file_idx1,file_idx2,idx = self.get_file_idx(idx-1990)\n",
        "      count = idx%10\n",
        "      count = count if (count!=0) else 10\n",
        "      \n",
        "      permute1,permute2,neg_idx = self.neg_permute(count,int(file_idx1))\n",
        "\n",
        "      img1 = Image.open(self.path+file_idx1+file_idx2+permute1+'.bmp')\n",
        "      img2 = Image.open(self.path+ neg_idx +file_idx2+permute2+'.bmp')\n",
        "      label = 0.\n",
        "      \n",
        "    img1 = autobots(img1)\n",
        "    img2 = autobots(img2)\n",
        "    img1 = img1.type(torch.float16)\n",
        "    img2 = img2.type(torch.float16)\n",
        "    label = torch.tensor([label],dtype=torch.float16)\n",
        "\n",
        "    return (img1,img2,label)\n",
        "\n",
        "mmu2 = mmu2_dataset()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1ow2lBrUPlj",
        "colab_type": "text"
      },
      "source": [
        "### combined dataset, split mmu2 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa0HcyEgDU_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = int(0.7 * len(mmu2))\n",
        "test_size = len(mmu2) - train_size\n",
        "\n",
        "# Split the mmu2 dataset into train and validation set\n",
        "mmu2_train, mmu2_test = torch.utils.data.random_split(mmu2, [train_size, test_size],generator=torch.Generator().manual_seed(2020))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq50vZZJDlpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a combined dataset from the two dataloader classes\n",
        "class combined_dataset(Dataset):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def __len__(self):\n",
        "    return (len(mmu2)+len(iitd))\n",
        "  def __getitem__(self, idx):\n",
        "    if idx<len(iitd):\n",
        "      return iitd[idx]\n",
        "    else:\n",
        "      idx = idx - len(iitd)\n",
        "      return mmu2_train[idx]\n",
        "\n",
        "combined = combined_dataset()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4HFTSOrKZaj",
        "colab_type": "text"
      },
      "source": [
        "### Training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OTHM-AjfBWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decay = []; no_decay = []; l2_reg = 4*10**(-5); # weight decay parameter\n",
        "\n",
        "# To avoid applying weight decay to the resNet50 parameters. \n",
        "# Also, decay is not applied to the bias parameters.\n",
        "for name, param in classifier.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    if len(param.shape) == 1 or name.endswith(\".bias\"): no_decay.append(param)\n",
        "    else: decay.append(param)\n",
        "\n",
        "parameters = [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': l2_reg}]    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZwp2Cu6FjGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size_batches = 256; no_batches = ceil(len(combined)/size_batches); \n",
        "\n",
        "# To enhance specificity (precision)\n",
        "sensitivity_weight = torch.tensor([0.4]); sensitivity_weight = sensitivity_weight.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=sensitivity_weight)\n",
        "\n",
        "#Learning rate and step decay\n",
        "optimizer = optim.SGD(parameters, lr=0.075, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4, gamma=0.9)\n",
        "\n",
        "# Define the data loaders\n",
        "trainloader = torch.utils.data.DataLoader(combined, batch_size=size_batches,shuffle=True, num_workers = 4)\n",
        "testloader = torch.utils.data.DataLoader(mmu2_test, batch_size=size_batches,shuffle=True, num_workers = 2)\n",
        "mmu2_trainloader = torch.utils.data.DataLoader(mmu2_train, batch_size=size_batches,shuffle=True, num_workers = 2)\n",
        "\n",
        "# path to save model\n",
        "path = '/content/drive/My Drive/iris detection/data/' "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIsPrhTwpH3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To compute accuracy on testloader while training\n",
        "def validation_accuracy():\n",
        "  acc=0;\n",
        "  classifier.eval()\n",
        "  for data in testloader:\n",
        "    img1, img2, lab = data\n",
        "    img1 = img1.to(device); img2 = img2.to(device);\n",
        "    img1 = img1.type(torch.cuda.FloatTensor); img2 = img2.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    out = classifier(img1,img2)\n",
        "    out = torch.sigmoid(out.cpu())\n",
        "    pred = out.detach().numpy()\n",
        "    lab = lab.numpy()\n",
        "    pred[pred>=0.5] = 1.\n",
        "    pred[pred<0.5] = 0.\n",
        "\n",
        "    acc += np.sum(pred==lab)\n",
        "\n",
        "  acc = round(acc/(len(mmu2_test)),4)*100\n",
        "  print('Validation Accuracy: {}'.format(acc))\n",
        "  print()\n",
        "  return acc"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-qMhmIKqRjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To compute accuracy on mmu2_trainloader while training\n",
        "def mmu2_train_accuracy():\n",
        "  acc=0;\n",
        "  classifier.eval()\n",
        "  for data in mmu2_trainloader:\n",
        "    img1, img2, lab = data\n",
        "    img1 = img1.to(device); img2 = img2.to(device);\n",
        "    img1 = img1.type(torch.cuda.FloatTensor); img2 = img2.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    out = classifier(img1,img2)\n",
        "    out = torch.sigmoid(out.cpu())\n",
        "    pred = out.detach().numpy()\n",
        "    lab = lab.numpy()\n",
        "    pred[pred>=0.5] = 1.\n",
        "    pred[pred<0.5] = 0.\n",
        "    acc += np.sum(pred==lab)\n",
        "\n",
        "  acc = round(acc/(len(mmu2_train)),4)*100\n",
        "  print('MMU2 Training Accuracy: {}'.format(acc))\n",
        "  print()\n",
        "  return acc"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlpkeJ5VFcQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To compute accuracy on trainloader while training i.e. whole training data\n",
        "def train_accuracy():\n",
        "  acc=0;\n",
        "  classifier.eval()\n",
        "  for data in trainloader:\n",
        "    img1, img2, lab = data\n",
        "    img1 = img1.to(device); img2 = img2.to(device);\n",
        "    img1 = img1.type(torch.cuda.FloatTensor); img2 = img2.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    out = classifier(img1,img2)\n",
        "    out = torch.sigmoid(out.cpu())\n",
        "    pred = out.detach().numpy()\n",
        "    lab = lab.numpy()\n",
        "    pred[pred>=0.5] = 1.\n",
        "    pred[pred<0.5] = 0.\n",
        "    acc += np.sum(pred==lab)\n",
        "\n",
        "  acc = round(acc/(len(combined)),4)*100\n",
        "  print('Complete Training Accuracy: {}'.format(acc))\n",
        "  print()\n",
        "  return acc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZfdJD6rGJ0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cea039e-afa7-4621-942c-2c44af095e9b"
      },
      "source": [
        "# training code!\n",
        "\n",
        "#Falaana dhimkana\n",
        "loss_values = []\n",
        "mmu2_train_acc = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times, duh\n",
        "  \n",
        "  classifier.train()\n",
        "  print('Epoch {}/{}'.format(epoch+1, 100))\n",
        "  print('-' * 10)\n",
        "\n",
        "  running_loss = 0.0\n",
        "    \n",
        "  for data in trainloader:\n",
        "    img1_batch, img2_batch, labels = data\n",
        "    img1_batch = img1_batch.to(device); img2_batch = img2_batch.to(device); labels = labels.to(device)\n",
        "\n",
        "    # BCE with logits loss somehow demands it\n",
        "    img1_batch = img1_batch.type(torch.cuda.FloatTensor); img2_batch = img2_batch.type(torch.cuda.FloatTensor);\n",
        "    labels = labels.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    outputs = classifier(img1_batch,img2_batch)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  scheduler.step()\n",
        "\n",
        "  # Compute loss every epoch\n",
        "  epoch_loss = (running_loss/no_batches)\n",
        "  loss_values.append(epoch_loss)\n",
        "\n",
        "  print('Loss: {:.4f}'.format(epoch_loss))\n",
        "  print()\n",
        "\n",
        "  # Compute and store accuracy every 5 epochs\n",
        "  if (((epoch+1)%5) == 0):\n",
        "    \n",
        "    mmu2_train_acc.append(mmu2_train_accuracy())\n",
        "    train_acc.append(train_accuracy())\n",
        "    val_acc.append(validation_accuracy())\n",
        "\n",
        "    # save the best model once validation accuracy reached 90 percent\n",
        "    if (val_acc[-1]>=90):\n",
        "      diff = train_acc[-1] - val_acc[-1]\n",
        "      index = len(val_acc)-1\n",
        "      for i in range(len(val_acc)-1):\n",
        "        if (val_acc[i]>=90)&((train_acc[i] - val_acc[i])<diff):\n",
        "          index = i\n",
        "      if (index==(len(val_acc)-1)):\n",
        "        torch.save(classifier.state_dict(), path+'model3 reg 4e-5.pth')\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "----------\n",
            "Loss: 0.4322\n",
            "\n",
            "Epoch 2/100\n",
            "----------\n",
            "Loss: 0.4207\n",
            "\n",
            "Epoch 3/100\n",
            "----------\n",
            "Loss: 0.4187\n",
            "\n",
            "Epoch 4/100\n",
            "----------\n",
            "Loss: 0.4187\n",
            "\n",
            "Epoch 5/100\n",
            "----------\n",
            "Loss: 0.4186\n",
            "\n",
            "MMU2 Training Accuracy: 50.32\n",
            "\n",
            "Complete Training Accuracy: 50.080000000000005\n",
            "\n",
            "Validation Accuracy: 49.25\n",
            "\n",
            "Epoch 6/100\n",
            "----------\n",
            "Loss: 0.4182\n",
            "\n",
            "Epoch 7/100\n",
            "----------\n",
            "Loss: 0.4131\n",
            "\n",
            "Epoch 8/100\n",
            "----------\n",
            "Loss: 0.3765\n",
            "\n",
            "Epoch 9/100\n",
            "----------\n",
            "Loss: 0.2981\n",
            "\n",
            "Epoch 10/100\n",
            "----------\n",
            "Loss: 0.2707\n",
            "\n",
            "MMU2 Training Accuracy: 68.84\n",
            "\n",
            "Complete Training Accuracy: 68.73\n",
            "\n",
            "Validation Accuracy: 68.17\n",
            "\n",
            "Epoch 11/100\n",
            "----------\n",
            "Loss: 0.2629\n",
            "\n",
            "Epoch 12/100\n",
            "----------\n",
            "Loss: 0.2567\n",
            "\n",
            "Epoch 13/100\n",
            "----------\n",
            "Loss: 0.2445\n",
            "\n",
            "Epoch 14/100\n",
            "----------\n",
            "Loss: 0.2419\n",
            "\n",
            "Epoch 15/100\n",
            "----------\n",
            "Loss: 0.2333\n",
            "\n",
            "MMU2 Training Accuracy: 83.09\n",
            "\n",
            "Complete Training Accuracy: 83.37\n",
            "\n",
            "Validation Accuracy: 79.31\n",
            "\n",
            "Epoch 16/100\n",
            "----------\n",
            "Loss: 0.2314\n",
            "\n",
            "Epoch 17/100\n",
            "----------\n",
            "Loss: 0.2214\n",
            "\n",
            "Epoch 18/100\n",
            "----------\n",
            "Loss: 0.2157\n",
            "\n",
            "Epoch 19/100\n",
            "----------\n",
            "Loss: 0.2115\n",
            "\n",
            "Epoch 20/100\n",
            "----------\n",
            "Loss: 0.2162\n",
            "\n",
            "MMU2 Training Accuracy: 86.0\n",
            "\n",
            "Complete Training Accuracy: 84.85000000000001\n",
            "\n",
            "Validation Accuracy: 80.4\n",
            "\n",
            "Epoch 21/100\n",
            "----------\n",
            "Loss: 0.2007\n",
            "\n",
            "Epoch 22/100\n",
            "----------\n",
            "Loss: 0.1920\n",
            "\n",
            "Epoch 23/100\n",
            "----------\n",
            "Loss: 0.1893\n",
            "\n",
            "Epoch 24/100\n",
            "----------\n",
            "Loss: 0.1762\n",
            "\n",
            "Epoch 25/100\n",
            "----------\n",
            "Loss: 0.1685\n",
            "\n",
            "MMU2 Training Accuracy: 90.88000000000001\n",
            "\n",
            "Complete Training Accuracy: 91.56\n",
            "\n",
            "Validation Accuracy: 83.5\n",
            "\n",
            "Epoch 26/100\n",
            "----------\n",
            "Loss: 0.1417\n",
            "\n",
            "Epoch 27/100\n",
            "----------\n",
            "Loss: 0.1323\n",
            "\n",
            "Epoch 28/100\n",
            "----------\n",
            "Loss: 0.1364\n",
            "\n",
            "Epoch 29/100\n",
            "----------\n",
            "Loss: 0.1207\n",
            "\n",
            "Epoch 30/100\n",
            "----------\n",
            "Loss: 0.1154\n",
            "\n",
            "MMU2 Training Accuracy: 91.17\n",
            "\n",
            "Complete Training Accuracy: 92.72\n",
            "\n",
            "Validation Accuracy: 83.08\n",
            "\n",
            "Epoch 31/100\n",
            "----------\n",
            "Loss: 0.1072\n",
            "\n",
            "Epoch 32/100\n",
            "----------\n",
            "Loss: 0.1070\n",
            "\n",
            "Epoch 33/100\n",
            "----------\n",
            "Loss: 0.0966\n",
            "\n",
            "Epoch 34/100\n",
            "----------\n",
            "Loss: 0.0958\n",
            "\n",
            "Epoch 35/100\n",
            "----------\n",
            "Loss: 0.0824\n",
            "\n",
            "MMU2 Training Accuracy: 93.72\n",
            "\n",
            "Complete Training Accuracy: 94.87\n",
            "\n",
            "Validation Accuracy: 83.84\n",
            "\n",
            "Epoch 36/100\n",
            "----------\n",
            "Loss: 0.0803\n",
            "\n",
            "Epoch 37/100\n",
            "----------\n",
            "Loss: 0.0719\n",
            "\n",
            "Epoch 38/100\n",
            "----------\n",
            "Loss: 0.0832\n",
            "\n",
            "Epoch 39/100\n",
            "----------\n",
            "Loss: 0.0672\n",
            "\n",
            "Epoch 40/100\n",
            "----------\n",
            "Loss: 0.0573\n",
            "\n",
            "MMU2 Training Accuracy: 92.96\n",
            "\n",
            "Complete Training Accuracy: 95.75\n",
            "\n",
            "Validation Accuracy: 83.0\n",
            "\n",
            "Epoch 41/100\n",
            "----------\n",
            "Loss: 0.0548\n",
            "\n",
            "Epoch 42/100\n",
            "----------\n",
            "Loss: 0.0500\n",
            "\n",
            "Epoch 43/100\n",
            "----------\n",
            "Loss: 0.0444\n",
            "\n",
            "Epoch 44/100\n",
            "----------\n",
            "Loss: 0.0421\n",
            "\n",
            "Epoch 45/100\n",
            "----------\n",
            "Loss: 0.0402\n",
            "\n",
            "MMU2 Training Accuracy: 97.31\n",
            "\n",
            "Complete Training Accuracy: 97.34\n",
            "\n",
            "Validation Accuracy: 87.86\n",
            "\n",
            "Epoch 46/100\n",
            "----------\n",
            "Loss: 0.0391\n",
            "\n",
            "Epoch 47/100\n",
            "----------\n",
            "Loss: 0.0381\n",
            "\n",
            "Epoch 48/100\n",
            "----------\n",
            "Loss: 0.0334\n",
            "\n",
            "Epoch 49/100\n",
            "----------\n",
            "Loss: 0.0292\n",
            "\n",
            "Epoch 50/100\n",
            "----------\n",
            "Loss: 0.0247\n",
            "\n",
            "MMU2 Training Accuracy: 98.82\n",
            "\n",
            "Complete Training Accuracy: 99.11\n",
            "\n",
            "Validation Accuracy: 87.19\n",
            "\n",
            "Epoch 51/100\n",
            "----------\n",
            "Loss: 0.0234\n",
            "\n",
            "Epoch 52/100\n",
            "----------\n",
            "Loss: 0.0234\n",
            "\n",
            "Epoch 53/100\n",
            "----------\n",
            "Loss: 0.0228\n",
            "\n",
            "Epoch 54/100\n",
            "----------\n",
            "Loss: 0.0182\n",
            "\n",
            "Epoch 55/100\n",
            "----------\n",
            "Loss: 0.0175\n",
            "\n",
            "MMU2 Training Accuracy: 99.64\n",
            "\n",
            "Complete Training Accuracy: 99.68\n",
            "\n",
            "Validation Accuracy: 88.27000000000001\n",
            "\n",
            "Epoch 56/100\n",
            "----------\n",
            "Loss: 0.0160\n",
            "\n",
            "Epoch 57/100\n",
            "----------\n",
            "Loss: 0.0147\n",
            "\n",
            "Epoch 58/100\n",
            "----------\n",
            "Loss: 0.0136\n",
            "\n",
            "Epoch 59/100\n",
            "----------\n",
            "Loss: 0.0132\n",
            "\n",
            "Epoch 60/100\n",
            "----------\n",
            "Loss: 0.0122\n",
            "\n",
            "MMU2 Training Accuracy: 99.89\n",
            "\n",
            "Complete Training Accuracy: 99.91\n",
            "\n",
            "Validation Accuracy: 87.77000000000001\n",
            "\n",
            "Epoch 61/100\n",
            "----------\n",
            "Loss: 0.0125\n",
            "\n",
            "Epoch 62/100\n",
            "----------\n",
            "Loss: 0.0112\n",
            "\n",
            "Epoch 63/100\n",
            "----------\n",
            "Loss: 0.0109\n",
            "\n",
            "Epoch 64/100\n",
            "----------\n",
            "Loss: 0.0104\n",
            "\n",
            "Epoch 65/100\n",
            "----------\n",
            "Loss: 0.0102\n",
            "\n",
            "MMU2 Training Accuracy: 99.92999999999999\n",
            "\n",
            "Complete Training Accuracy: 99.94\n",
            "\n",
            "Validation Accuracy: 88.53\n",
            "\n",
            "Epoch 66/100\n",
            "----------\n",
            "Loss: 0.0093\n",
            "\n",
            "Epoch 67/100\n",
            "----------\n",
            "Loss: 0.0092\n",
            "\n",
            "Epoch 68/100\n",
            "----------\n",
            "Loss: 0.0086\n",
            "\n",
            "Epoch 69/100\n",
            "----------\n",
            "Loss: 0.0082\n",
            "\n",
            "Epoch 70/100\n",
            "----------\n",
            "Loss: 0.0078\n",
            "\n",
            "MMU2 Training Accuracy: 99.75\n",
            "\n",
            "Complete Training Accuracy: 99.85000000000001\n",
            "\n",
            "Validation Accuracy: 88.44\n",
            "\n",
            "Epoch 71/100\n",
            "----------\n",
            "Loss: 0.0077\n",
            "\n",
            "Epoch 72/100\n",
            "----------\n",
            "Loss: 0.0073\n",
            "\n",
            "Epoch 73/100\n",
            "----------\n",
            "Loss: 0.0071\n",
            "\n",
            "Epoch 74/100\n",
            "----------\n",
            "Loss: 0.0069\n",
            "\n",
            "Epoch 75/100\n",
            "----------\n",
            "Loss: 0.0069\n",
            "\n",
            "MMU2 Training Accuracy: 100.0\n",
            "\n",
            "Complete Training Accuracy: 99.97\n",
            "\n",
            "Validation Accuracy: 87.86\n",
            "\n",
            "Epoch 76/100\n",
            "----------\n",
            "Loss: 0.0067\n",
            "\n",
            "Epoch 77/100\n",
            "----------\n",
            "Loss: 0.0063\n",
            "\n",
            "Epoch 78/100\n",
            "----------\n",
            "Loss: 0.0064\n",
            "\n",
            "Epoch 79/100\n",
            "----------\n",
            "Loss: 0.0060\n",
            "\n",
            "Epoch 80/100\n",
            "----------\n",
            "Loss: 0.0059\n",
            "\n",
            "MMU2 Training Accuracy: 100.0\n",
            "\n",
            "Complete Training Accuracy: 99.97\n",
            "\n",
            "Validation Accuracy: 87.94\n",
            "\n",
            "Epoch 81/100\n",
            "----------\n",
            "Loss: 0.0057\n",
            "\n",
            "Epoch 82/100\n",
            "----------\n",
            "Loss: 0.0057\n",
            "\n",
            "Epoch 83/100\n",
            "----------\n",
            "Loss: 0.0056\n",
            "\n",
            "Epoch 84/100\n",
            "----------\n",
            "Loss: 0.0054\n",
            "\n",
            "Epoch 85/100\n",
            "----------\n",
            "Loss: 0.0053\n",
            "\n",
            "MMU2 Training Accuracy: 100.0\n",
            "\n",
            "Complete Training Accuracy: 99.97\n",
            "\n",
            "Validation Accuracy: 88.19\n",
            "\n",
            "Epoch 86/100\n",
            "----------\n",
            "Loss: 0.0053\n",
            "\n",
            "Epoch 87/100\n",
            "----------\n",
            "Loss: 0.0052\n",
            "\n",
            "Epoch 88/100\n",
            "----------\n",
            "Loss: 0.0051\n",
            "\n",
            "Epoch 89/100\n",
            "----------\n",
            "Loss: 0.0050\n",
            "\n",
            "Epoch 90/100\n",
            "----------\n",
            "Loss: 0.0050\n",
            "\n",
            "MMU2 Training Accuracy: 100.0\n",
            "\n",
            "Complete Training Accuracy: 99.97\n",
            "\n",
            "Validation Accuracy: 88.11\n",
            "\n",
            "Epoch 91/100\n",
            "----------\n",
            "Loss: 0.0049\n",
            "\n",
            "Epoch 92/100\n",
            "----------\n",
            "Loss: 0.0048\n",
            "\n",
            "Epoch 93/100\n",
            "----------\n",
            "Loss: 0.0047\n",
            "\n",
            "Epoch 94/100\n",
            "----------\n",
            "Loss: 0.0046\n",
            "\n",
            "Epoch 95/100\n",
            "----------\n",
            "Loss: 0.0046\n",
            "\n",
            "MMU2 Training Accuracy: 100.0\n",
            "\n",
            "Complete Training Accuracy: 99.98\n",
            "\n",
            "Validation Accuracy: 88.36\n",
            "\n",
            "Epoch 96/100\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-43e99e1a02df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mimg1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg1_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mimg2_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAuz0uZifGAa",
        "colab_type": "text"
      },
      "source": [
        "### Plot curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk8C5s5bLcJa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "79c78e67-efda-4418-d61e-d19e5f70ca09"
      },
      "source": [
        "plt.plot(loss_values)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fef90230550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix5JgbywTTj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0a5c79c4-f00e-43d3-d82d-bc8dfd65f6fb"
      },
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3b6K_KZ_eOP",
        "colab_type": "text"
      },
      "source": [
        "### Save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy6-SxxTXypL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save\n",
        "path = '/content/drive/My Drive/iris detection/data/'\n",
        "torch.save(classifier.state_dict(), path+'model3 reg 4e-5.pth')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0OTKRrK_v94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load\n",
        "model1 = iris_classifier0()\n",
        "model1.load_state_dict(torch.load('/content/drive/My Drive/iris detection/data/model1_100.pth'))\n",
        "model1 = model1.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwA46pzec5rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load\n",
        "model3 = iris_classifier()\n",
        "model3.load_state_dict(torch.load('/content/drive/My Drive/iris detection/data/model3 reg 4e-5.pth'))\n",
        "model3 = model3.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKNRe9mI_iU6",
        "colab_type": "text"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kW_V7ls_-WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b61477e-0129-46d8-b527-012641cac186"
      },
      "source": [
        "# Accuracy and other metrics of the model\n",
        "\n",
        "acc=0;tp=0;tn=0;fp=0;fn=0\n",
        "model3.eval()\n",
        "\n",
        "for data in testloader:\n",
        "  img1_batch, img2_batch, labels = data\n",
        "  img1_batch = img1_batch.to(device); img2_batch = img2_batch.to(device);\n",
        "  img1_batch = img1_batch.type(torch.cuda.FloatTensor); img2_batch = img2_batch.type(torch.cuda.FloatTensor)\n",
        "\n",
        "  out = model3(img1_batch,img2_batch)\n",
        "  out = torch.sigmoid(out.cpu())\n",
        "  predict = out.detach().numpy()\n",
        "  labels = labels.numpy()\n",
        "  predict[predict>=0.5] = 1.\n",
        "  predict[predict<0.5] = 0.\n",
        "\n",
        "  for i in range(len(labels)):\n",
        "    if (labels[i,0]==1.)&(predict[i,0]==1.):\n",
        "      tp +=1\n",
        "    if (labels[i,0]==0.)&(predict[i,0]==1.):\n",
        "      fp +=1\n",
        "    if (labels[i,0]==1.)&(predict[i,0]==0.):\n",
        "      fn +=1\n",
        "    if (labels[i,0]==0.)&(predict[i,0]==0.):\n",
        "      tn +=1\n",
        "  acc += np.sum(predict==labels)\n",
        "\n",
        "acc = round(acc/(3980*0.3),4)*100\n",
        "speci = round(tn/(tn+fp),4)*100\n",
        "sensi = round(tp/(tp+fn),4)*100\n",
        "\n",
        "print('Accuracy: {} Specificity: {} Sensitivity: {}'.format(acc,speci,sensi))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 88.36 Specificity: 83.16 Sensitivity: 93.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEg3sY7WV1Kl",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYI8YI1mTcBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=0;\n",
        "model2.eval()\n",
        "for data in trainloader:\n",
        "  img1_batch, img2_batch, labels = data\n",
        "  img1_batch = img1_batch.to(device); img2_batch = img2_batch.to(device);\n",
        "  img1_batch = img1_batch.type(torch.cuda.FloatTensor); img2_batch = img2_batch.type(torch.cuda.FloatTensor)\n",
        "\n",
        "  out = model2(img1_batch,img2_batch)\n",
        "  out = torch.sigmoid(out.cpu())\n",
        "  predict = out.detach().numpy()\n",
        "  labels = labels.numpy()\n",
        "  predict[predict>=0.5] = 1.\n",
        "  predict[predict<0.5] = 0.\n",
        "  acc += np.sum(predict==labels)\n",
        "\n",
        "acc = round(acc/(len(combined)),4)*100\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqvXi2SAbSYZ",
        "colab_type": "text"
      },
      "source": [
        "### Original classifier (Scheme 1) - only if you want to load model 1 and model 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvtMuq4YWZPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cff1eaa-50ac-4d56-d0ee-febe042a1823"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # this model was working.\n",
        "print(device)\n",
        "class iris_classifier0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(iris_classifier0, self).__init__()\n",
        "    self.resNet50 = models.resnet50(pretrained=True)\n",
        "    # Here you get the bottleneck/feature extractor\n",
        "    modules=list(self.resNet50.children())[:-1]\n",
        "    self.resNet50 = torch.nn.Sequential(*modules)\n",
        "\n",
        "    self.resNet50.flat = torch.nn.Flatten()\n",
        "    \n",
        "    for param in self.resNet50.parameters():\n",
        "      param.requires_grad = False # freeze all layers of the convnet\n",
        "    \n",
        "    self.fc1 = nn.Linear(2048,1024)\n",
        "    self.fc2 = nn.Linear(1024,128)\n",
        "    self.fc3 = nn.Linear(256,16)\n",
        "    self.fc4 = nn.Linear(16,1)\n",
        "\n",
        "    # Set your own forward pass\n",
        "  def forward(self, img1, img2):\n",
        "    self.resNet50.eval()\n",
        "    out1 = self.resNet50(img1)\n",
        "    out2 = self.resNet50(img2)\n",
        "    \n",
        "    out1 = F.relu(self.fc1(out1))\n",
        "    out2 = F.relu(self.fc1(out2))\n",
        "    out1 = F.relu(self.fc2(out1))\n",
        "    out2 = F.relu(self.fc2(out2))\n",
        "\n",
        "    out = torch.cat((out1,out2),1)\n",
        "\n",
        "    out = F.relu(self.fc3(out))\n",
        "    out = self.fc4(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}